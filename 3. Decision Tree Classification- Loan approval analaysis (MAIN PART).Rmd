
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, message=FALSE, warning=FALSE}
#install.packages("C50")
library(C50)
library(gmodels)

# load data
data <- read.csv("Loans_processed.csv")
mean(data$term)/12
#set seed
set.seed(1)

# shuffle data
loans <- data[sample(nrow(data), nrow(data)), ]

# training data (20,000)
training <- loans[1 : 20000, ]

# validationn data (8,000)
validation <- loans[20001:28000, ]

# testing data (remaining data)
test <- loans[28001: nrow(loans), ]

# accuracy threshold
acc_threshold <- sum(loans$loan_status == 'Fully Paid') / (sum(loans$loan_status == 'Fully Paid') + sum(loans$loan_status == 'Charged Off'))
# result -> 85.954%

# run C50 with training set
training_model <- C5.0(training[, 1:7], training[, 8])
# summary(training_model)

#training_boost <- C5.0(training[, 1:7], training[, 8], trials = 10)

# predict with training set using training model
training_r <- predict.C5.0(training_model, training[, 1:7], type = "class")
sum(training_r == training[, 8]) / length(training_r)

# predict with validation set using training model
validation_result <- predict.C5.0(training_model, validation[, 1:7], type = "class")
#summary(validation_result)
sum(validation_result == validation[, 8]) / length(validation_result)

#validation_result_boost <-  predict.C5.0(training_boost, validation[, 1:7], type = "class")

# confusion matrix
cm1 <- CrossTable(validation[, 8], validation_result,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))

#CrossTable(validation[, 8], validation_result_boost,
#           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
#           dnn = c('actual', 'predicted'))

# error cost matrix
error_cost1 <- matrix(c(0, 14, 1, 0), nrow = 2) 
rownames(error_cost1) <- colnames(error_cost1) <- c("Charged Off", "Fully Paid")

error_cost2 <- matrix(c(0, 30, 1, 0), nrow = 2) 
rownames(error_cost2) <- colnames(error_cost2) <- c("Charged Off", "Fully Paid")

error_cost3 <- matrix(c(0, 48, 1, 0), nrow = 2) 
rownames(error_cost3) <- colnames(error_cost3) <- c("Charged Off", "Fully Paid")

# training with error cost and boost
training_model_e1 <- C5.0(training[, 1:7], training[, 8], costs = error_cost1, trials = 10)
# summary(training_model_e1)

training_model_e2 <- C5.0(training[, 1:7], training[, 8], costs = error_cost2, trials = 10)
# summary(training_model_e2)

training_model_e3 <- C5.0(training[, 1:7], training[, 8], costs = error_cost3, trials = 10)
# summary(training_model_e3)

# predict with validation set using training model and error cost
validation_result_e1 <- predict.C5.0(training_model_e1, validation[, 1:7], type = "class")
sum(validation_result_e1 == validation[, 8]) / length(validation_result_e1) # accuracy

validation_result_e2 <- predict.C5.0(training_model_e2, validation[, 1:7], type = "class")
sum(validation_result_e2 == validation[, 8]) / length(validation_result_e2) # accuracy

validation_result_e3 <- predict.C5.0(training_model_e3, validation[, 1:7], type = "class")
sum(validation_result_e3 == validation[, 8]) / length(validation_result_e3) # accuracy

# confusion matrix
cm_e1 <- CrossTable(validation[, 8], validation_result_e1,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))

# ~25% sensitivity (24.23%)
cm_e1$t[1,1]/(cm_e1$t[1,1] + cm_e1$t[1,2])

# precision
cm_e1$t[1,1]/(cm_e1$t[1,1] + cm_e1$t[2,1])

# confusion matrix
cm_e2 <- CrossTable(validation[, 8], validation_result_e2,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))

# ~40% sensitivity (38.77%)
cm_e2$t[1,1]/(cm_e2$t[1,1] + cm_e2$t[1,2])

# precision
cm_e2$t[1,1]/(cm_e2$t[1,1] + cm_e2$t[2,1])

cm_e3 <- CrossTable(validation[, 8], validation_result_e3,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))

# ~50% sensitivity (51.52%)
cm_e3$t[1,1]/(cm_e3$t[1,1] + cm_e3$t[1,2])

# precision
cm_e3$t[1,1]/(cm_e3$t[1,1] + cm_e3$t[2,1])

# write classification tree to text
write(capture.output(summary(training_model_e1)), "training-model-e1.txt")
write(capture.output(summary(training_model_e2)), "training-model-e2.txt")
write(capture.output(summary(training_model_e3)), "training-model-e3.txt")

senselist <- c(0.2423, 0.3877, 0.5152)
preclist <- c(0.3075, 0.2741, 0.238)

# sensitivity vs precision
plot(senselist, preclist)

# test set result
test_result <- predict.C5.0(training_model_e3, test[, 1:7], type = "class")
cm_e4 <- CrossTable(test[, 8], test_result,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))

# sensitivity
cm_e4$t[1,1]/(cm_e4$t[1,1] + cm_e4$t[1,2])

# precision
cm_e4$t[1,1]/(cm_e4$t[1,1] + cm_e4$t[2,1])
```


